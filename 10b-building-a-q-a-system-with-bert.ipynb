{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 10b\n! pip install transformers torch tokenizers\n\n#: Importing the Necessary Libraries\n\nfrom transformers import BertForQuestionAnswering, BertTokenizer\nimport torch\n# Loading the Pre-trained BERT Model and Tokenizer\n\n# Load the pre-trained BERT tokenizer and model for question answering\ntokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\nmodel = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n\n\n#  Function to Answer Questions Using BERT\n\ndef answer_question(question, context):\n    # Tokenize the input question and context\n    inputs = tokenizer.encode_plus(question, context, return_tensors='pt')\n    \n    # Get model's predicted start and end positions of the answer\n    with torch.no_grad():\n        outputs = model(**inputs)\n        start_scores = outputs.start_logits\n        end_scores = outputs.end_logits\n\n    # Get the most likely start and end token positions\n    start_index = torch.argmax(start_scores)\n    end_index = torch.argmax(end_scores)\n\n    # Convert token indices to tokens and then join them into a single string answer\n    answer_tokens = inputs['input_ids'][0][start_index: end_index + 1]\n    answer = tokenizer.decode(answer_tokens)\n\n    return answer\ndef main():\n    # Get user input for context once\n    context = input(\"\\nProvide the context (paragraph): \")\n\n    while True:\n        # Get user input for the question\n        question = input(\"Ask a question (or type 'exit' to quit): \")\n\n        # Exit the system if the user types 'exit'\n        if question.lower() in ['exit', 'quit']:\n            print(\"Exiting the Q&A system.\")\n            break\n\n        # Get the answer from the BERT model\n        answer = answer_question(question, context)\n        print(f\"Answer: {answer}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-10-18T18:56:06.946798Z","iopub.execute_input":"2024-10-18T18:56:06.947147Z","iopub.status.idle":"2024-10-18T18:57:34.406758Z","shell.execute_reply.started":"2024-10-18T18:56:06.947104Z","shell.execute_reply":"2024-10-18T18:57:34.405747Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (0.20.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e39a5e7183e14634b0bc5b4ae7b1baa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0a443e2a82a44bca44623cc8f3620b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5197a143a7dd424dbbc002b5afde7d93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2c33899cf8342779841aa19f2420aa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7040151db78545feb2d9c63c7b44597b"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nProvide the context (paragraph):  python is a programming language. it is a high level programming language\nAsk a question (or type 'exit' to quit):  what is the programming language\n"},{"name":"stdout","text":"Answer: python\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Ask a question (or type 'exit' to quit):  which is high level programming language\n"},{"name":"stdout","text":"Answer: python\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Ask a question (or type 'exit' to quit):  exit\n"},{"name":"stdout","text":"Exiting the Q&A system.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}